{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "a = df_train[df_train[\"class\"] == 1].sample(3500)\n",
    "\n",
    "b = pd.concat([df_train[df_train[\"class\"] == 0], a])\n",
    "\n",
    "c = pd.concat([df_train[df_train[\"class\"] == 2], b])\n",
    "\n",
    "df_train = c\n",
    "\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.lower() # lowercase\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r\"http\\S+\", '') # remove url\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r'\\s*rt\\s*@[^:]*:*', '') #rt\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r'\\$\\w*', '')\n",
    "\n",
    "\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.lower() # lowercase\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r\"http\\S+\", '') # remove url\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r'\\s*rt\\s*@[^:]*:*', '') #rt\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r'\\$\\w*', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: nltk.tokenize.casual.remove_handles(x)) # remove tagged user\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: nltk.tokenize.casual.remove_handles(x)) # remove tagged user\n",
    "\n",
    "\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r'\\d+(\\.\\d+)?', '') # remove number\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r'[^\\w\\d\\s]', '') # remove punctuation\n",
    "#df_train[\"tweet\"] = df_train[\"tweet\"].str.replace(r'&#d+;', '') # remove emoji\n",
    "\n",
    "#df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r'&#d+;', '') # remove emoji                                   \n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r'\\d+(\\.\\d+)?', '') # remove number\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].str.replace(r'[^\\w\\d\\s]', '') # remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some = [\"im\", \"u\", \"get\", \"like\", \"lol\", \"bitch\", \"nigga\", \"niggas\"]\n",
    "\n",
    "some = [\"im\", \"u\"]\n",
    "\n",
    "for i in stop_words:\n",
    "    some.append(re.sub(r'[^\\w\\d\\s]', '',i))\n",
    "    \n",
    "some = set(some)\n",
    "\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: ' '.join(term for term in x.split() if term not in some))\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: ' '.join(term for term in x.split() if term not in some))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "lemmatizer = SnowballStemmer(\"english\")\n",
    "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: ' '.join(lemmatizer.stem(term) for term in x.split()))\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: ' '.join(lemmatizer.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "tokenizer = TweetTokenizer().tokenize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[\"tweet\"], df_train[\"class\"], test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_grid = {\"num_leaves\": [10,15,20,25,30], \"max_depth\": [5,10,15,20,30]}\\ngrid = GridSearchCV(LGBMClassifier(), param_grid=param_grid, verbose=3)\\ngrid.fit(X_train, y_train)\\ngrid.predict(X_test)\\nprint(grid.best_score_)\\nprint(grid.best_params_)\\n\\nnames = [\"K near\", \"Decision tree\", \"random forest\", \"SGD\", \"naive bayes\", \"linear SVC\"]\\nclassifiers = [KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(),\\n               SGDClassifier(max_iter = 100), MultinomialNB(), LinearSVC(loss=\\'hinge\\')]\\n\\nmodels = [(\"K near\", KNeighborsClassifier()), (\"Decision tree\", DecisionTreeClassifier()),\\n          (\"random forest\", RandomForestClassifier()), (\"SGD\", SGDClassifier(max_iter=100)),\\n          (\"naive bayes\", MultinomialNB()), (\"linear SVC\", LinearSVC(loss=\\'hinge\\'))]\\n\\nensemble = VotingClassifier(estimators = models, voting=\"hard\", n_jobs=-1)\\nensemble.fit(X_train, y_train)\\npp = ensemble.predict(X_test)\\n'"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, tokenizer=tokenizer)\n",
    "tfidf_vectorizer.fit(df_train[\"tweet\"])\n",
    "\n",
    "\n",
    "X_train = tfidf_vectorizer.transform(X_train).toarray()\n",
    "X_test = tfidf_vectorizer.transform(X_test).toarray()\n",
    "\n",
    "\n",
    "real_train = tfidf_vectorizer.transform(df_train[\"tweet\"]).toarray()\n",
    "real_test = tfidf_vectorizer.transform(df_test[\"tweet\"]).toarray()\n",
    "\n",
    "#model = LGBMClassifier(max_depth=10, num_leaves=25)\n",
    "model = LinearSVC(loss=\"hinge\")\n",
    "model.fit(real_train, df_train[\"class\"])\n",
    "pp = model.predict(real_test)\n",
    "\n",
    "'''\n",
    "param_grid = {\"num_leaves\": [10,15,20,25,30], \"max_depth\": [5,10,15,20,30]}\n",
    "grid = GridSearchCV(LGBMClassifier(), param_grid=param_grid, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.predict(X_test)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "names = [\"K near\", \"Decision tree\", \"random forest\", \"SGD\", \"naive bayes\", \"linear SVC\"]\n",
    "classifiers = [KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "               SGDClassifier(max_iter = 100), MultinomialNB(), LinearSVC(loss='hinge')]\n",
    "\n",
    "models = [(\"K near\", KNeighborsClassifier()), (\"Decision tree\", DecisionTreeClassifier()),\n",
    "          (\"random forest\", RandomForestClassifier()), (\"SGD\", SGDClassifier(max_iter=100)),\n",
    "          (\"naive bayes\", MultinomialNB()), (\"linear SVC\", LinearSVC(loss='hinge'))]\n",
    "\n",
    "ensemble = VotingClassifier(estimators = models, voting=\"hard\", n_jobs=-1)\n",
    "ensemble.fit(X_train, y_train)\n",
    "pp = ensemble.predict(X_test)\n",
    "'''\n",
    "#accuracy_score(pp, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.38      0.45       222\n",
      "          1       0.87      0.87      0.87      1079\n",
      "          2       0.85      0.92      0.89       763\n",
      "\n",
      "avg / total       0.83      0.84      0.83      2064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  id\n",
       "0      1   0\n",
       "1      2   1\n",
       "2      1   2\n",
       "3      1   3\n",
       "4      1   4"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd = pd.DataFrame({\"id\": df_test[\"id\"], \"class\": pd.Series(pp)})\n",
    "result_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_csv(\"result.csv\",columns=['id','class'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
